{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T17:32:49.125036Z",
     "start_time": "2018-09-16T17:32:46.880272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import statsmodels.api as sm\n",
    "from scipy.interpolate import interp1d\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test target data from the provided URL and convert the timestamp column to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test target data URL: https://raw.githubusercontent.com/Jialunx/GEFCom/refs/heads/main/TestTar_W.csv\n",
    "\n",
    "# hint\n",
    "# test_target = pd.read_csv('...')\n",
    "# test_target['TIMESTAMP'] = pd.to_datetime(test_target['TIMESTAMP'])\n",
    "# test_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the training and test data**\n",
    "\n",
    "Steps to follow:\n",
    "1. Initialize dictionaries to store training and test data\n",
    "3. Load training data from URL\n",
    "4. Convert timestamp column to datetime\n",
    "5. Load test data from URL\n",
    "6. Convert timestamp column to datetime\n",
    "7. Merge test data with test_target on ZONEID and TIMESTAMP\n",
    " \n",
    "(Note that test data URL does not include target value, hence, we merge \"test_target\" to test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data URL: https://raw.githubusercontent.com/Jialunx/GEFCom/refs/heads/main/Train_W_Zone1.csv\n",
    "# test data URL: https://raw.githubusercontent.com/Jialunx/GEFCom/refs/heads/main/TestPred_W_Zone1.csv\n",
    "\n",
    "# hint\n",
    "# train_data = {}\n",
    "# test_data = {}\n",
    "# train_data = pd.read_csv(f'...')\n",
    "# train_data['TIMESTAMP'] = pd.to_datetime(...)\n",
    "# test_data = pd.read_csv(f'...')\n",
    "# test_data['TIMESTAMP'] = pd.to_datetime(...)\n",
    "# test_data = pd.merge(test_target,test_data)\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\t**ZONEID**: Zone ID for each wind farm, ranging from 1 to 10. For this workshop, we only look at Zone 1.  \n",
    "•\t**TIMESTAMP**: Date and time for each recorded observation.  \n",
    "•\t**TARGETVAR**: The normalized power output of the wind farm during the given hour, ranging from 0 and 1.                     \n",
    "•\t**U10**: East-west component of the forecasted wind vector at 10 meters above ground level. Positive values indicate wind blowing eastward.  \n",
    "•\t**V10**: North-south component of the forecasted wind vector at 10 meters above ground level. Positive values indicate wind blowing northward.  \n",
    "•\t**U100**: East-west component of the forecasted wind vector at 100 meters above ground level. Positive values indicate wind blowing eastward.  \n",
    "•\t**V100**: North-south component of the forecasted wind vector at 100 meters above ground level. Positive values indicate wind blowing northward.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the relationship between the wind forecasts at 100 meters and the power output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint\n",
    "# train_data.plot.scatter(x = '...',y = '...', c = '...', figsize = (...), colormap = '...', alpha = ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate features**\n",
    "\n",
    "Steps to follow:\n",
    "1. Calculate wind speeds at 100m and 10m using U and V components\n",
    "2. Calculate average wind speed between 100m and 10m\n",
    "3. Calculate wind direction angles at both heights using arctan2\n",
    "4. Combine training and test data for each zone into one dataframe\n",
    "\n",
    "**wind speed at 100m:** ws100 = sqrt(U100^2 + V100^2)\\\n",
    "**wind speed at 10m:** ws10 = sqrt(U10^2 + V10^2) \\\n",
    "**average wind speed:** ws_avg = (ws100 + ws10)/2\\\n",
    "**wind direction at 100m:** angle100 = arctan2(V100, U100) * 180/pi\\\n",
    "**wind direction at 10m:** angle10 = arctan2(V10, U10) * 180/pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint:\n",
    "# train_data['ws100'] = np.sqrt(train_data['U100']**2 + train_data['V100']**2)\n",
    "# train_data['ws10'] = ...\n",
    "# train_data['ws_avg'] = ...\n",
    "# train_data['polar_angle100'] = (180 / np.pi) * np.arctan2(train_data['V100'], train_data['U100'])\n",
    "# train_data['polar_angle10'] = ...\n",
    "\n",
    "# Same features for the test set\n",
    "# test_data['ws100'] = ...\n",
    "#   ...\n",
    "\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the power generation and wind speed at 100m over time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "#fig, ax1 = plt.subplots(figsize=(12,3))\n",
    "#ax2 = ax1.twinx()\n",
    "#ins1 = ax1.plot(train_data['TARGETVAR'][:500], 'k', label='Wind Power')\n",
    "#ins2 = ax2.plot(train_data[...][...], '...' , label=...)\n",
    "#ax1.set_xlabel('Time')\n",
    "#ax1.set_ylabel(...)\n",
    "#ax2.set_ylabel(...)\n",
    "#ax1.set_title(...)\n",
    "#plt.grid(alpha=...)\n",
    "#ax2.legend(ins1 + ins2, ['Wind Power', 'Wind Speed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using heatmap to plot the correlation between input features and target power generation for different zones**\n",
    "\n",
    "Steps to follow:\n",
    "1. Initialize an empty DataFrame for correlations\n",
    "2. calculate correlations (drop 'ZONEID','TIMESTAMP' columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint\n",
    "#corr_df = pd.DataFrame()\n",
    "#corr_arr = train_data.drop(columns=[...]).corrwith(train_data['TARGETVAR'])\n",
    "#corr_df = pd.concat([corr_df, corr_arr.rename(f'Power generation')], axis=1)\n",
    "    \n",
    "#fig, ax = plt.subplots(figsize=(3, 3))\n",
    "#sns.heatmap(..., annot=True, ax=ax)\n",
    "#plt.title('...')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benchmark**\n",
    "\n",
    "To evaluate prediction accuracy, it’s helpful to set a benchmark model. Here, the benchmark predicts the current month’s value as the average of the same month last year and the previous month.\n",
    "\n",
    "Steps to follow:\n",
    "1. Create a copy of training data and set timestamps as index\n",
    "2.  - Get actual test values from previous data \"test_target\", which is from **'2013-12-01 01:00:00' to '2014-01-01 00:00:00'**\n",
    "    - Estimate values by averaging same dates from:\\\n",
    "    **'2012-12-01 01:00:00' to '2013-01-01 00:00:00'**\\\n",
    "    **'2013-10-31 01:00:00' to '2013-12-01 00:00:00'**  \n",
    "3. Compare actual vs estimated values using RMSE\n",
    "4. Plot actual vs estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint:\n",
    "#temp_train = train_data\n",
    "#temp_train = temp_train.set_index('TIMESTAMP')\n",
    "\n",
    "#actual_values = test_data['...']\n",
    "#estimated_values = ((temp_train['2012-12-01 01:00:00':'2013-01-01 00:00:00']['TARGETVAR'].reset_index(drop=True) + ...)/2)\n",
    "\n",
    "#comparison_df = pd.DataFrame({'actual': actual_values, 'estimate': estimated_values})\n",
    "#comparison_df.dropna(inplace=True)  #drop the nan values\n",
    "#benchmark_rmse = np.sqrt(mse(..., ...))\n",
    "#print(f'Benchmark RMSE is {benchmark_rmse:.4f}')  #(Benchmark RMSE is 0.2774)\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(16,3))\n",
    "#ax.plot(actual_values,color='r',label='Estimated Power Generation')\n",
    "#...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Layer Perceptron (MLP)**\n",
    "\n",
    "In this notebook, we will use a single validation subset instead of cross-validation to reduce computational cost. The training data will be split into a training subset and a validation subset, with the validation subset comprising the most recent 10% of the data (approximately two months).\\\n",
    "The model's architecture, including the number of layers, neurons, and other hyperparameters, will be determined based on its performance on this validation set.\n",
    "\n",
    "Steps to follow:\n",
    "1. split training data into 90% train and 10% validation\n",
    "2. rearrange train and validation into input and target\\\n",
    "     For input, keep all features for now (except TARGETVAR,  TIMESTAMP column)\\\n",
    "     For target, only keep TARGETVAR column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "#split_limit = int(len(train_data) * 0.9)\n",
    "#train = pd.concat([train_data.iloc[:split_limit, :]])\n",
    "#eval = pd.concat([train_data.iloc[... , ...]])\n",
    "\n",
    "#print(train.sample(5).to_string(index=True))\n",
    "\n",
    "#def prepare_data(data, target_column='TARGETVAR', drop_column='TIMESTAMP'):\n",
    "    #data = data.drop([drop_column], axis=1).dropna().reset_index(drop=True)\n",
    "    #x = data.drop(target_column, axis=1).values\n",
    "    #y = data[...].values\n",
    "    #return x, y\n",
    "\n",
    "#x_train, y_train = prepare_data(train)\n",
    "#x_valid, y_valid = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build 2-layer NN model with 64 neurons in each layer.\\\n",
    "To prevent overfitting, an early stoppage can be applied to stop the training process at a point when performance on a validation set decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2-layer NN model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)),  # First hidden layer\n",
    "    layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    layers.Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "# Add Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[early_stopping],  # Stop if no improvement\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions = model.predict(x_valid)\n",
    "\n",
    "# Optional: Calculate RMSE manually for verification\n",
    "rmse = np.sqrt(mse(y_valid, predictions))\n",
    "print(f'Calculated validation RMSE: {rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fast training time is due to relatively simple dataset (9 datapoint as input and 1 datapoint as output) and model structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot trainind and validation loss\n",
    "train_loss = history.history['root_mean_squared_error']\n",
    "val_loss = history.history['val_root_mean_squared_error']\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.title('Training and Validation Loss', fontsize=10)\n",
    "plt.xlabel('Epoch', fontsize=10)\n",
    "plt.ylabel('Loss (RMSE)', fontsize=10)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use above trained model to check the model performance on test data. Plot the prediction result for test data and compare to benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "#x_test, y_test = prepare_data(test_data)\n",
    "#predictions = model.predict(...)\n",
    "#rmse = np.sqrt(mse(..., ...))\n",
    "#print(f'test RMSE: {rmse:.4f}')\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(16,3))\n",
    "#ax.plot(\n",
    "#    actual_values.dropna().reset_index(drop=True), \n",
    "#    color='k', \n",
    "#    label='Actual Power Generation'\n",
    "#)\n",
    "#...\n",
    "#ax.set_xlabel('Time [hour]')\n",
    "#ax.set_ylabel('Power')\n",
    "#ax.legend(loc='upper left')\n",
    "#ax.set_title(\"Power Generation and Wind Speed over Time\")\n",
    "#plt.grid(linestyle='--', alpha=0.4)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tDrop **ZONEID** as input features as we only use 1 zone in this workshop, and it is expect that it does not contribute to the predictive power.\n",
    "2.\tTry remove or add other features to see the difference in RMSE for validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def prepare_data(data, target_column='TARGETVAR', drop_columns=['TIMESTAMP', 'ZONEID', 'polar_angle100', 'polar_angle10']):  #try different features\n",
    "#    data = data.drop(drop_columns, axis=1).dropna().reset_index(drop=True) \n",
    "#    x = data.drop(target_column, axis=1).values\n",
    "#    y = data[target_column].values\n",
    "#    return x, y\n",
    "\n",
    "#x_train, y_train = prepare_data(train)\n",
    "#x_valid, y_valid = prepare_data(eval)\n",
    "#print(x_train.shape)    #check data shape\n",
    "#print(y_train.shape)\n",
    "\n",
    "#model = models.Sequential([\n",
    "#    layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)),  \n",
    "#    layers.Dense(64, activation='relu'),  \n",
    "#    layers.Dense(1)  \n",
    "#])\n",
    "#model.compile(\n",
    "#    optimizer='adam',\n",
    "#    loss='mse',\n",
    "#    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "#)\n",
    "#early_stopping = EarlyStopping(\n",
    "#    monitor='val_loss', \n",
    "#    patience=20, \n",
    "#    restore_best_weights=True, \n",
    "#    verbose=0\n",
    "#)\n",
    "#history = model.fit(\n",
    "#    x_train, y_train,\n",
    "#    epochs=50,\n",
    "#    batch_size=64,\n",
    "#    validation_data=(x_valid, y_valid),\n",
    "#    callbacks=[early_stopping],  \n",
    "#    verbose=0\n",
    "#)\n",
    "#predictions = model.predict(x_valid)\n",
    "#rmse = np.sqrt(mse(y_valid, predictions))\n",
    "#print(f'Calculated validation RMSE: {rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory, incorporating the power output from the past few hours, along with forecasted changes in wind speed for the preceding and upcoming hours, could improve prediction accuracy. However, in practical applications, wind power forecasting is typically performed 24 to 48 hours ahead of real-time, making it impractical to use recent power output as an input. Instead, forecasted wind speeds from both previous and upcoming hours can be included as additional features to enhance the model's predictive performance. \n",
    "\n",
    "**Include the past wind speeds 'ws100' as the input to the model**\n",
    "\n",
    "For the ease of the comparision, we can build a pipeline to streamline the process of evaluating different features and tuning hyperparameters. This will make it easier to compare performance across various configurations efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "#def run_nn_pipeline(train_data, eval_data, target_column='TARGETVAR', drop_columns=['TIMESTAMP', 'ZONEID'], \n",
    "#                    hidden_units=64, activation='relu', optimizer='adam', loss='mse', \n",
    "#                    patience=10, epochs=50, batch_size=64, verbose=0):\n",
    "    \n",
    "# Prepare data \n",
    "#    def prepare_data(data, target_column, drop_columns):\n",
    "#        data = data.drop(columns=drop_columns, errors='ignore').dropna().reset_index(drop=True)\n",
    "#        x = data.drop(columns=[target_column], errors='ignore').values\n",
    "#        y = data[target_column].values\n",
    "#        return x, y\n",
    "\n",
    "#    x_train, y_train = prepare_data(train_data, target_column, drop_columns)\n",
    "#    x_valid, y_valid = prepare_data(eval_data, target_column, drop_columns)\n",
    "\n",
    "    # Build model\n",
    "#    model = models.Sequential([\n",
    "#        layers.Dense(...),\n",
    "#        layers.Dense(...),\n",
    "#        layers.Dense(1)\n",
    "#    ])\n",
    "\n",
    "    # Compile and train\n",
    "#    model.compile(optimizer=optimizer, loss=loss, metrics=['RootMeanSquaredError'])\n",
    "    \n",
    "#    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "#    model.fit(\n",
    "#       x_train, y_train,\n",
    "#       epochs=...\n",
    "#       batch_size=...\n",
    "#       validation_data=...\n",
    "#       callbacks=...\n",
    "#       verbose=...\n",
    "#   )\n",
    "\n",
    "    # Evaluate on test set\n",
    "#    predictions = model.predict(x_valid)\n",
    "#    rmse = np.sqrt(mse(y_valid, predictions))\n",
    "#    print(f'Test RMSE: {rmse:.5f}')\n",
    "\n",
    "#    return model, rmse, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add lag value of past 1 to 10 hours and check if the RMSE drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "#split_limit = int(len(train_data) * 0.9)\n",
    "#train = pd.concat([train_data.iloc[:split_limit, :]])\n",
    "#eval = pd.concat([train_data.iloc[split_limit:, :]])\n",
    "\n",
    "#error = {}\n",
    "#for lag in range(0,11):\n",
    "#        train['ws100_lag{}'.format(lag)] = train['ws100'].shift(lag)\n",
    "#        eval['ws100_lag{}'.format(lag)] = ...\n",
    "#        model, rmse, predictions = run_nn_pipeline(\n",
    "#                    train_data=train,\n",
    "#                    eval_data=eval,\n",
    "#                    target_column='TARGETVAR',\n",
    "#                    drop_columns=['TIMESTAMP', 'ZONEID'],  # Drop additional columns if needed\n",
    "#                    hidden_units=...,\n",
    "#                    patience=...,\n",
    "#                    epochs=...,\n",
    "#                    batch_size=...\n",
    "#        )\n",
    "#        error[lag] = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the lag result\n",
    "for i in range(0,11):\n",
    "    print('RMSE for {:2} speed lag is {}'.format(i,error[i]))\n",
    "\n",
    "lag_num = min(error, key=error.get)\n",
    "print('The optimal number of speed lags to add is {} and the corresponding RMSE is {:.4}'\n",
    "      .format(lag_num, error[lag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the optimal number of acceleration lags to the original set\n",
    "split_limit = int(len(train_data) * 0.9)\n",
    "train = pd.concat([train_data.iloc[:split_limit, :]])\n",
    "eval = pd.concat([train_data.iloc[split_limit:, :]])\n",
    "test = test_data\n",
    "\n",
    "for lag in range(1,lag_num+1):\n",
    "        train['ws100_lag{}'.format(lag)] = train['ws100'].shift(lag)\n",
    "        eval['ws100_lag{}'.format(lag)] = eval['ws100'].shift(lag)\n",
    "        test['ws100_lag{}'.format(lag)] = test['ws100'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data shape\n",
    "print(train.shape)\n",
    "print(eval.shape)\n",
    "print(test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To procceed to hyperparameter tuning, we can further improve the **run_nn_pipeline** function to include number of layers and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn_pipeline(train_data, eval_data, test_data, target_column='TARGETVAR', drop_columns=['TIMESTAMP', 'ZONEID'], \n",
    "                    hidden_units=64, \n",
    "                    num_layers=2, # add num_layer\n",
    "                    activation='relu', optimizer='adam', loss='mse', \n",
    "                    patience=10, epochs=50, batch_size=64, verbose=1, rmse_type='test'):\n",
    "    \n",
    "    # Prepare data\n",
    "    def prepare_data(data, target_column, drop_columns):\n",
    "        data = data.drop(columns=drop_columns, errors='ignore').dropna().reset_index(drop=True)\n",
    "        x = data.drop(columns=[target_column], errors='ignore').values\n",
    "        y = data[target_column].values\n",
    "        return x, y\n",
    "\n",
    "    x_train, y_train = prepare_data(train_data, target_column, drop_columns)\n",
    "    x_valid, y_valid = prepare_data(eval_data, target_column, drop_columns)\n",
    "    x_test, y_test = prepare_data(test_data, target_column, drop_columns)\n",
    "#-------------------------------------\n",
    "\n",
    "    model = models.Sequential()\n",
    "    # Add the input layer\n",
    "    model.add(layers.Dense(hidden_units, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    # Add the hidden layers\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(layers.Dense(hidden_units, activation=activation))\n",
    "    # Add the output layer\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "#--------------------------------------\n",
    " \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['RootMeanSquaredError'])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    if rmse_type == 'validation':\n",
    "        predictions = model.predict(x_valid)\n",
    "        rmse = np.sqrt(mse(y_valid, predictions))\n",
    "    elif rmse_type == 'test':\n",
    "        predictions = model.predict(x_test)\n",
    "        rmse = np.sqrt(mse(y_test, predictions))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid rmse_type. Choose 'validation' or 'test'.\")\n",
    "\n",
    "    print(f'Calculated {rmse_type.capitalize()} RMSE: {rmse:.5f}')\n",
    "\n",
    "    return model, rmse, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "# #results = {}\n",
    "\n",
    "# Iterate over layers and neurons\n",
    "#for i in range(...):  # Number of layer\n",
    "#    for j in range(...):  # Number of neurons (multiples of 32)\n",
    "#        model, rmse, predictions = run_nn_pipeline(\n",
    "#            train_data=train,\n",
    "#            eval_data=eval,\n",
    "#            test_data=test_data,\n",
    "#            target_column='TARGETVAR',\n",
    "#            drop_columns=['TIMESTAMP', 'ZONEID'], \n",
    "#            hidden_units=j,  \n",
    "#            num_layers=i,  \n",
    "#            activation='relu', \n",
    "#            optimizer='adam', \n",
    "#            loss='mse',  \n",
    "#            patience=10,\n",
    "#            epochs=50,\n",
    "#            batch_size=64,\n",
    "#            verbose=0,\n",
    "#            rmse_type='validation'\n",
    "#        )\n",
    "\n",
    "        # Store RMSE for each combination of neurons and layers\n",
    "#        results[(i, j)] = rmse\n",
    "\n",
    "        # Print the result for the current combination\n",
    "#        print(f\"Number of layers: {i}, Number of neurons: {j}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Find the combination with the minimum RMSE\n",
    "#optimal_combination = min(results, key=results.get)\n",
    "#optimal_neurons, optimal_layers = optimal_combination\n",
    "#optimal_rmse = results[optimal_combination]\n",
    "\n",
    "#print(f'\\nThe optimal number of neurons = {optimal_layers}, layers = {optimal_neurons}, and the corresponding RMSE is {optimal_rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the optimised parameter and train and test the model on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "# Iterate over layers and neurons\n",
    "\n",
    "model, rmse, predictions = run_nn_pipeline(\n",
    "            train_data=train,\n",
    "            eval_data=eval,\n",
    "            test_data=test,\n",
    "            target_column='TARGETVAR',\n",
    "            drop_columns=['TIMESTAMP'],  # Drop additional columns if needed\n",
    "            hidden_units=128,  # Number of neurons\n",
    "            num_layers=3,  # Number of layers\n",
    "            activation='relu', \n",
    "            optimizer='adam', \n",
    "            loss='mse',  \n",
    "            patience=10,\n",
    "            epochs=50,\n",
    "            batch_size=64,\n",
    "            verbose=0,\n",
    "            rmse_type='test'\n",
    "        )\n",
    "\n",
    "        # Store RMSE for each combination of neurons and layers\n",
    "results = rmse\n",
    "\n",
    "# Print the optimal result\n",
    "print(f'\\nThe test RMSE is {results:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = prepare_data(test, 'TARGETVAR', ['TIMESTAMP'])\n",
    "prediction = model(x_test)  # ML prediction on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the prediction result to the theoretical model**\n",
    "\n",
    "Using the provided operational curve, interpolate the curve to estimate the power output for the wind speeds in the test data. Assume the wind farm has an operational capacity of 400 MW, based on 40 wind turbines. Scale both the theoretical predictions from the curve and the ML model predictions to 400 MW for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind speed (U) in m/s\n",
    "U = [4, 5, 6, 7, 8, 9, 10, 11, 11.17, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "# Power output (MW) \n",
    "Power = [0.459, 0.897, 1.55, 2.462, 3.674, 5.232, 7.177, 9.552, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(U, Power, 'k', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Wind Speed [m/s]')\n",
    "plt.ylabel('Power Output [MW]')\n",
    "plt.title('Operational curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint\n",
    "# can use interp1d function to interpolate power output for given wind speeds\n",
    "\n",
    "#scaling = 400 \n",
    "#test = test.dropna().reset_index(drop=True)\n",
    "#actual_values = test['TARGETVAR'] * scaling\n",
    "#wind_speed = test['ws100']\n",
    "\n",
    "# Interpolate power output for given wind speeds with extrapolation\n",
    "#interpolated_power = ... * scaling / 10\n",
    "\n",
    "\n",
    "# Scaling the predicted values\n",
    "#scaled_prediction = prediction * scaling\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(12, 3))\n",
    "#...\n",
    "\n",
    "# Calculating RMSE for ML and theoretical predictions\n",
    "#rmse_ML = np.sqrt(mse(scaled_prediction, actual_values))/scaling\n",
    "#rmse_theory = np.sqrt(mse(interpolated_power, actual_values))/scaling\n",
    "\n",
    "# Printing the RMSE\n",
    "#print(f'ML RMSE is {rmse_ML:.4f}')\n",
    "#print(f'Theoretical RMSE is {rmse_theory:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "370.6px",
    "left": "752px",
    "right": "20px",
    "top": "98px",
    "width": "503px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
